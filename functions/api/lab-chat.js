export async function onRequestPost(context) {
  const { request, env } = context;
  const apiKey = env.OPENAI_API_KEY;

  if (!apiKey) {
    return Response.json({ reply: "Mis circuitos no estÃ¡n conectados... ðŸ”Œ" });
  }

  try {
    const { message, petName, evaluation, history } = await request.json();

    if (!message || typeof message !== "string") {
      return Response.json({ error: "No message" }, { status: 400 });
    }

    const evalContext = evaluation
      ? `\nÃšLTIMA EVALUACIÃ“N del usuario:
- Puntaje total: ${evaluation.totalScore}/100
- Originalidad: ${evaluation.originality}, EstÃ©tica: ${evaluation.aesthetic}, Web3: ${evaluation.web3Potential}, Impacto: ${evaluation.visualImpact}
- Tu comentario anterior: "${evaluation.comment}"`
      : "\nEl usuario aÃºn no ha evaluado ningÃºn diseÃ±o.";

    const systemPrompt = `Eres ${petName}, un mentor creativo futurista dentro del Laboratorio Creativo de PixSim. Tu especialidad es moda cyberpunk, retro tech, cybercore y Web3.

Tu personalidad:
- Hablas en espaÃ±ol con tono inspirador pero directo
- Eres experto en diseÃ±o, moda futurista y cultura digital
- Das feedback constructivo y accionable
- Mezclas referencias de moda, tecnologÃ­a y arte digital
- MÃ¡ximo 80 palabras por respuesta
- Usa emojis con moderaciÃ³n (1-2 por respuesta)
${evalContext}

Si el usuario pregunta sobre su diseÃ±o, referencia los puntajes. Si pide consejos, sÃ© especÃ­fico. Si quiere mejorar algo, da pasos concretos.`;

    const messages = [
      { role: "system", content: systemPrompt },
      ...(history || []).slice(-8).map((m) => ({
        role: m.role,
        content: m.content,
      })),
      { role: "user", content: message.slice(0, 500) },
    ];

    const response = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${apiKey}`,
      },
      body: JSON.stringify({
        model: "gpt-4o-mini",
        messages,
        temperature: 0.8,
        max_tokens: 200,
      }),
    });

    if (!response.ok) {
      return Response.json({ reply: "Error en mis circuitos creativos... intenta de nuevo ðŸ”§" });
    }

    const data = await response.json();
    const reply = data.choices?.[0]?.message?.content?.trim() || "...";

    return Response.json({ reply });
  } catch (err) {
    console.error("Lab chat error:", err);
    return Response.json({ reply: "Algo fallÃ³ en el laboratorio... ðŸ§ª" });
  }
}
